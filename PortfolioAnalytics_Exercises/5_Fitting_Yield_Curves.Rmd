---
title: "5. Fitting Yield Curves"
author: "Alexis Sciau"
date: "08/04/2020"
output:
  html_document:
    code_folding: hide
    df_print: kable
    theme: default
    toc: yes
    toc_float: yes
    toc_depth: 4 
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loading libraries, echo=TRUE, message=FALSE, warning=FALSE}
library(data.table)
library(lubridate)
library(ggplot2)
library(pracma)
library(fasttime)
library(xts)
library(YieldCurve)
theme_set(theme_minimal())
```

## 5.1 Getting started
Though we do not have access to the same data as the book, ie a collection of US Treasury bond yields as at 29 May 2009, we retrieve from the [US treasury website](https://www.treasury.gov/resource-center/data-chart-center/interest-rates/Pages/TextView.aspx?data=yield "Daily Treasury Yield Curve Rates  from US Treasury") the daily treasury yield curve rates. Plotting this curve, we expect to get something close to the fig 5.2.

```{r US_yield_curve_example, message=FALSE, warning=FALSE}
yc_dt <- fread("../data/data_YC_US")
yc_dt[,index:=fastPOSIXct(index)]
yc_dt[,index:=as.Date(index)]
yc_xts <- as.xts(yc_dt)

tenors <- c(1/12,2/12,3/12,6/12,1,2,3,5,7,10,20,30)
colnames(yc_xts)<-tenors

rates <- yc_xts["20090528/20090603"]

daily_data <- as.data.table(melt(as.data.table(rates), measure.vars = colnames(rates)))
daily_data[,index_f := as.factor(index)]
daily_data[,tenors := as.numeric(as.character(variable))]
ggplot(daily_data,aes(x=tenors,y=value,color=index_f,group=index_f))+ scale_x_continuous(name="Tenors", limits=c(0, 30)) + geom_point() + geom_smooth(se=FALSE)
```

## 5.2 Yield Curves 101

### 5.2.1 Pure-Discount Bond Prices
We note that, in this paragraph, the author take the assumption that the interest rate can't be less than zero :

> "Some reflection reveals that the price should not exceed $1. Paying more than the future value essentially implies a negative interest rate [...]"

This fairly logical assumption does not hold today!

### 5.2.2 Spot Rates
We will illustrate the correspondance between pure-discount bond prices and spot rates. We start this exercise choosing arbitrary prices for Pure-Discount bonds.
```{r Discount prices and spot rates}
long_names <- c("Maturity","Time to maturity","Pure-Discount Bond Price","Return","Rate","Simply compounded spot rates","Continuously compounded spot rates")
short_names <- c("mat","time_to_mat","disc_f","return","rate","spot_sc","spot_cc")
dt_rates <- as.data.table(as.Date(c("2020-04-30","2020-06-30","2020-12-31","2021-12-31","2025-12-31")))
dt_rates[,time_to_mat:=V1-as.Date("2020-04-17")]
dt_rates[,disc_f:=c(0.9995,0.997,0.985,0.95,0.82)]
dt_rates[,return := 1/disc_f]
dt_rates[,rate:=(return -1)*100]
dt_rates[,spot_sc:=(return^(365/as.numeric(time_to_mat))-1)*100]
dt_rates[,spot_cc:=(-log(disc_f)/(as.numeric(time_to_mat)/365))*100]
colnames(dt_rates)<-long_names
dt_rates
dt_rates_plot <- melt(dt_rates,id = 2,measure=c(6,7))
colnames(dt_rates_plot)<-c("time_to_mat","Rates","value")
ggplot(dt_rates_plot,aes(x=time_to_mat,y=value,color=Rates)) + geom_point() + geom_line() + scale_x_continuous(name="Time to maturity (days)") + scale_y_continuous(name="Rate (%)")
```

The above graph illustrates the impact of the time to maturity on the difference between simply compounded and continuously compounded rates.

### 5.2.3 Par Yields
Let's now compute the par-yields for the set of bonds used just before.
```{r par_yields}
colnames(dt_rates)<-short_names
dt_rates[,df_cumsum:=cumsum(disc_f)]
dt_rates[,par_yield:=(1-disc_f)/df_cumsum*100]
```

### 5.2.5 Bringing it all together
Let's suppose the rates given by the US treasury are spot rates, ie zero-coupon bond rates. We will therefor try to plot the subsequent par-yield and implied-forward artes curves. Also, to ease-up the work, we will not consider tenors under 1 year. Finally, we do simple linear interpolation to complete the zero-bond curve every year.
```{r all_together, warning=FALSE}
all_rates <- as.data.table(yc_xts["20090529"])
all_rates <- melt(all_rates,id=1,measure=6:13)
all_rates[,tenors:=as.numeric(as.character(variable))]
all_rates[,spot_rates:=value]
all_rates[,c("index"):=NULL][,c("variable"):=NULL][,c("value"):=NULL]
all_tenors <- data.table(tenors=1:30)
all_rates <- merge(all_rates,all_tenors,all=TRUE)
all_rates <- as.data.table(na.approx(all_rates))
all_rates[,disc_f:=1/(1+spot_rates/100)^tenors]
all_rates[,df_cumsum := cumsum(disc_f)]
all_rates[,par_yield:=((1-disc_f)/df_cumsum)*100]
all_rates[,disc_f_30:=all_rates[tenors==30,disc_f]]
all_rates[,T_minus_s:=30-tenors]
all_rates[,forward_rates_mat_30:=((disc_f/disc_f_30)^(1/T_minus_s)-1)*100]
all_rates[,df_shift:=shift(disc_f,1,type="lead")]
all_rates[,forward_rates_1y:=(disc_f/df_shift-1)*100]
all_rates_plot<-melt(all_rates,id="tenors",measure=c("spot_rates","par_yield","forward_rates_mat_30","forward_rates_1y"))
ggplot(all_rates_plot,aes(x=tenors,y=value,color=variable)) + geom_point() + geom_line()
ggplot(all_rates,aes(x=tenors,y=disc_f))+ geom_point() + geom_line()
```


The hypothesis used before, being that imput rates are spot rates, is not satisfactory whene it comes to rate modelling. We want to use par rates as input for the observed price !

Thus, we will do again the exercise in order to derive the spot rates from the par yields.

```{r all_together_from_par_yields}
all_rates <- as.data.table(yc_xts["20090529"])
all_rates <- melt(all_rates,id=1,measure=c(2,4:13))
all_rates[,tenor:=as.numeric(as.character(variable))]
all_rates[,par_rate:=value]
all_rates[,c("index"):=NULL][,c("variable"):=NULL][,c("value"):=NULL]
all_tenors <- data.table(tenor=1:30)
all_rates <- merge(all_rates,all_tenors,all=TRUE)
all_rates <- as.data.table(na.approx(all_rates))

all_rates[tenor<1,df:=1/(1+par_rate/100*tenor)]

par2df <- function(y){
  df <- rep.int(0,length(y))
  df[1] <- 1/(1+y[1]/100)
  for (i in 2:length(y)){
    df[i] <- (1-(y[i]/100)*sum(df[1:(i-1)]))/(y[i]/100+1)
  }
  return(df)
}

all_rates[tenor>=1,df:=par2df(par_rate)]

all_rates[,spot_rate:=((1/df)^(1/tenor)-1)*100]
all_rates[,df_cumsum := cumsum(df)]
all_rates[,disc_f_30:=all_rates[tenor==30,df]]
all_rates[,T_minus_s:=30-tenor]
all_rates[,forward_rates_mat_30:=((df/disc_f_30)^(1/T_minus_s)-1)*100]
all_rates[,df_shift:=shift(df,1,type="lead")]
all_rates[,forward_rates_1y:=(df/df_shift-1)*100]
all_rates_plot<-melt(all_rates,id="tenor",measure=c("spot_rate","par_rate","forward_rates_mat_30","forward_rates_1y"))
ggplot(all_rates_plot,aes(x=tenor,y=value,color=variable)) + geom_point() + geom_line()
ggplot(all_rates,aes(x=tenor,y=df))+ geom_point() + geom_line()
```

## 5.3 Curve Fitting

### 5.3.1 The Classic Approach
In this approach, several functions are taken as example to represent the four core consituents of the yield curve. We will go through the examples chosen in the book.s

#### 5.3.1.1 Discount factors as negative exponential
The first example is to choose the negative exponential to represent the discount factors.

```{r negative_exp_df}
disc_f <- function(t,a=0.03,x=0){
  exp(-a*(t-x))
}
ex1_dt <- data.table(t=seq(0,30,0.1))
ex1_dt[,disc_factors_1 := disc_f(t,0.01)]
ex1_dt[,disc_factors_2 := disc_f(t,0.02)]
ex1_dt[,disc_factors_3 := disc_f(t,0.03)]
ex1_dt[,disc_factors_4 := disc_f(t,0.04)]
ex1_dt[,disc_factors_5 := disc_f(t,0.05)]
ex1_dt[,disc_factors_6 := disc_f(t,0.06)]
ex1_dt[,disc_factors_7 := disc_f(t,0.07)]
ex1_dt[,zero_coupon_1 := -log(disc_factors_1)/t*100]
ex1_dt[,zero_coupon_2 := -log(disc_factors_2)/t*100]
ex1_dt[,zero_coupon_3 := -log(disc_factors_3)/t*100]
ex1_dt[,zero_coupon_4 := -log(disc_factors_4)/t*100]
ex1_dt[,zero_coupon_5 := -log(disc_factors_5)/t*100]
ex1_dt[,zero_coupon_6 := -log(disc_factors_6)/t*100]
ex1_dt[,zero_coupon_7 := -log(disc_factors_7)/t*100]
ex1_dt_df_plot <- melt(ex1_dt,id="t",measure = c(2:8))
ex1_dt_zc_plot <- melt(ex1_dt,id="t",measure = c(9:15))
ggplot(ex1_dt_df_plot,aes(x=t,y=value,color=variable)) + geom_line()
ggplot(ex1_dt_zc_plot,aes(x=t,y=value,color=variable)) + geom_line() + scale_y_continuous(limits = c(0,10))
```

Numerically, we found back what is outlined in the book : using a negative exponential for representing discount factors leads to a flat zero coupon curve, equals to the parameter used in the negative exponential.

Finally, we are going to find the best choice for the parameter a, given the negative exponential form of the discount factors. We thus need to solve the optimisation problem outlined in the book.

Solving this problem using the R in-built optimisation functions requires one to express it in a matrix format. For now on, we will not dive into oprimisation problems. We will solve this problem numerically, for bonds with tenors <= 1, so that the annualy-compounded price function is straight-forward to write. 

```{r best_param_a}
prices_optim <- as.data.table(yc_xts["20090529"])

prices_optim_less_than_1 <- melt(prices_optim,id=1,measure = c(2,4:6))
a <- data.table(a=seq(0,2,0.0001))
a[,index:=rep(as.Date("2009-05-29"),.N)]
prices_optim_less_than_1 <- merge(prices_optim_less_than_1,a,allow.cartesian = TRUE)
prices_optim_less_than_1[,c("index"):=NULL]
colnames(prices_optim_less_than_1) <- c("tenor","par_rate","a")
prices_optim_less_than_1[,tenor:=as.numeric(as.character(tenor))]
prices_optim_less_than_1[,price := (1+par_rate/100)/(1+a/100)^(tenor)]
prices_optim_less_than_1[,norm_diff:= (price-1)^2]
prices_optim_less_than_1[,sum_norm_diff := sum(norm_diff),by=a]
ggplot(prices_optim_less_than_1,aes(x=a,y=sum_norm_diff))+geom_line()
prices_optim_less_than_1[sum_norm_diff == min(sum_norm_diff),a][1]
```

Numerically, we find that the best parameter for a is 0,5055. This is consistent with the result found in Excel.

We know can try to solve the same problema with coutinous compounding limiting ourselves to the same tenors.

```{r best_param_a_continous}
prices_optim_less_than_1_continuous <- melt(prices_optim,id=1,measure = c(2,4:6))
a <- data.table(a=seq(0,2,0.0001))
a[,index:=rep(as.Date("2009-05-29"),.N)]
prices_optim_less_than_1_continuous <- merge(prices_optim_less_than_1_continuous,a,allow.cartesian = TRUE)
prices_optim_less_than_1_continuous[,c("index"):=NULL]
colnames(prices_optim_less_than_1_continuous) <- c("tenor","par_rate","a") 
prices_optim_less_than_1_continuous[,tenor:=as.numeric(as.character(tenor))]
prices_optim_less_than_1_continuous[,price := (1+par_rate/100)*exp(-a/100*tenor)]
prices_optim_less_than_1_continuous[,norm_diff:= (price-1)^2]
prices_optim_less_than_1_continuous[,sum_norm_diff := sum(norm_diff),by=a]
ggplot(prices_optim_less_than_1_continuous,aes(x=a,y=sum_norm_diff))+geom_line()
prices_optim_less_than_1_continuous[sum_norm_diff == min(sum_norm_diff),a][1]
```

The value of the parameter a is quite close using the continuously compounded formula.

We will now try to find the good parameter a for taking into account all tenors. To do so, we will write function for the price of the bond.

```{r best_parameter_a_all_tenors}
price_sc <- function(t,y,z){
  price <- 0
  if (t<=1) {
    price <- (1+y/100)/(1+z/    100)^(t)
  } else {
    for (i in 1:t){
      price <- price + (y/100)/(1+z/100)^(i)
    }
    price <- price + 1/(1+z/100)^(t)
  }
  return(price)
}
prices_optim <- as.data.table(yc_xts["20090529"])

prices_optim_all <- melt(prices_optim,id=1,measure = c(2,4:13))
a <- data.table(a=seq(0,10,0.01))
a[,index:=rep(as.Date("2009-05-29"),.N)]
prices_optim_all <- merge(prices_optim_all,a,allow.cartesian = TRUE)
prices_optim_all[,c("index"):=NULL]
colnames(prices_optim_all) <- c("tenor","par_rate","a")
prices_optim_all[,tenor:=as.numeric(as.character(tenor))]
prices_optim_all[,price := mapply(price_sc,prices_optim_all[,tenor],prices_optim_all[,par_rate],prices_optim_all[,a])]
prices_optim_all[,norm_diff:= (price-1)^2]
prices_optim_all[,sum_norm_diff := sum(norm_diff),by=a]
ggplot(prices_optim_all,aes(x=a,y=sum_norm_diff))+geom_line()
prices_optim_all[sum_norm_diff == min(sum_norm_diff),a][1]

```

Finally, we can plot the par yield point against our toy model and get a figure that looks like fig 5.11.
```{r fig_5_11}
fig_5_11 <- as.data.table(yc_xts["20090529"])
fig_5_11 <- melt(fig_5_11,id=1,measure = c(2,4:13))
fig_5_11[,index:=NULL]
colnames(fig_5_11) <- c("tenor","par_rate")
fig_5_11[,tenor:=as.numeric(as.character(tenor))]
fig_5_11[,toy_model:=rep.int(prices_optim_all[sum_norm_diff == min(sum_norm_diff),a][1],.N)]
ggplot(fig_5_11, aes(x=tenor)) + geom_point(aes(y=par_rate)) + geom_line(aes(y=toy_model)) + scale_y_continuous(name = "Per cent") 
```

#### 5.3.1.2 Nelson-Siegel Model

Now that we manage to fit our toy model, we are going to fit a more complex Nelson-Siegel Model to our rates. First, we wil do so using an existing package : YieldCurve

```{r fitting_NS}
rates <- yc_xts["20090529"][,-c(2)]
matu <- as.numeric(colnames(rates))
NSParameters <- Nelson.Siegel(rate = rates, maturity = matu)
y <- NSrates(NSParameters[1,], matu)
plot(matu,rates,main="Fitting Nelson-Siegel yield curve",
  xlab=c("Pillars"), type="o")
lines(matu,y, col=2)
legend("topleft",legend=c("observed yield curve","fitted yield curve"),
col=c(1,2),lty=1)
grid()
```

We will now try to fit the model ourselves. In this package, we used par
```{r fitting_NS_man}
NS_fit <- as.data.table(yc_xts["20090529"])

NS_fit <- melt(NS_fit,id=1,measure = c(2,4:13))

a_0 <- data.table(a_0=seq(-5,5,0.5))
a_0[,index:=rep(as.Date("2009-05-29"),.N)]

a_1 <- data.table(a_1=seq(-5,5,0.5))
a_1[,index:=rep(as.Date("2009-05-29"),.N)]

a_2 <- data.table(a_2=seq(-5,5,0.5))
a_2[,index:=rep(as.Date("2009-05-29"),.N)]

lambda <- data.table(lambda=seq(0.1,1,0.05))
lambda[,index:=rep(as.Date("2009-05-29"),.N)]

NS_fit <- merge(NS_fit,a_0,allow.cartesian = TRUE)
NS_fit <- merge(NS_fit,a_1,allow.cartesian = TRUE)
NS_fit <- merge(NS_fit,a_2,allow.cartesian = TRUE)
NS_fit <- merge(NS_fit,lambda,allow.cartesian = TRUE)

price_NS <- function(t,y,a_0,a_1,a_2,lambda){
  price <- 0
  if (t<=1) {
    price <- (1+y/100)/(1+(a_0+a_1*(1-exp(-lambda*t))/(lambda*t)+a_2*((1-exp(-lambda*t))/(lambda*t)-exp(-lambda*t)))/100)^(t)
  } else {
    for (i in 1:t){
      price <- price + (y/100)/(1+(a_0+a_1*(1-exp(-lambda*t))/(lambda*t)+a_2*((1-exp(-lambda*t))/(lambda*t)-exp(-lambda*t)))/100)^(i)
    }
    price <- price + 1/(1+(a_0+a_1*(1-exp(-lambda*t))/(lambda*t)+a_2*((1-exp(-lambda*t))/(lambda*t)-exp(-lambda*t)))/100)^(t)
  }
  return(price)
}

NS_fit[,c("index"):=NULL]
colnames(NS_fit) <- c("tenor","par_rate","a_0","a_1","a_2","lambda")
NS_fit[,tenor:=as.numeric(as.character(tenor))]
NS_fit[,price := mapply(price_NS,NS_fit[,tenor],NS_fit[,par_rate],NS_fit[,a_0],NS_fit[,a_1],NS_fit[,a_2],NS_fit[,lambda])]
NS_fit[,norm_diff:= (price-1)^2]
NS_fit[,sum_norm_diff := sum(norm_diff),by=.(a_0,a_1,a_2,lambda)]
paramNS <- NS_fit[sum_norm_diff == min(sum_norm_diff),.(a_0,a_1,a_2,lambda)][1]


z <- function(t,a_0,a_1,a_2,lambda){
  a_0+a_1*(1-exp(-lambda*t))/(lambda*t)+a_2*((1-exp(-lambda*t))/(lambda*t)-exp(-lambda*t))
}

fig_5_13 <- as.data.table(yc_xts["20090529"])
fig_5_13 <- melt(fig_5_13,id=1,measure = c(2,4:13))
fig_5_13[,index:=NULL]
colnames(fig_5_13) <- c("tenor","par_rate")
fig_5_13[,tenor:=as.numeric(as.character(tenor))]
fig_5_13[,NS_model:=z(tenor,paramNS[1,a_0][1],paramNS[1,a_1][1],paramNS[1,a_2][1],paramNS[1,lambda][1])]
fig_5_13_plot <- melt(fig_5_13,id="tenor")
ggplot(fig_5_13_plot,aes(x=tenor,y=value,color=variable)) + geom_line()
```

The result is quite close !

#### 5.3.1.3 Svensson Model
The package *YieldCurve* used previously enables us to simply test the Svensson model. The svensson model extends the Nelson-Siegel models and enables the yield curve to take a second hump.

```{r fitting_Svensson}
rates <- yc_xts["20090529"][,-c(2)]
matu <- as.numeric(colnames(rates))
SParameters <- Svensson(rate = rates, maturity = matu)
y <- Srates(SParameters[1,], matu,"Spot")
plot(matu,rates,main="Fitting Svensson yield curve",
  xlab=c("Pillars"), type="o")
lines(matu,y, col=2)
legend("topleft",legend=c("observed yield curve","fitted yield curve"),
col=c(1,2),lty=1)
grid()
```

It is noteworthy that the svensson model used here returns spot rates and not par-rates.